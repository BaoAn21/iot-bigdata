docker compose -f docker-compose.yml up
docker compose -f docker-compose.yml down


python producer.py

/Users/tranan/Desktop/dev/spark/spark-3.5.1-bin-hadoop3/bin/spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1 \
  --master local\[4\] \
  Streaming.py

/Users/tranan/Desktop/dev/spark/spark-3.5.1-bin-hadoop3/bin/spark-submit --packages org.mongodb.spark:mongo-spark-connector_2.12:10.2.2 \
--master local\[4\] \
Batch.py

kafka-topics --bootstrap-server localhost:9092 --delete --topic electricity-usage

admin-pass mongo-express

python meter-producer.py 
python spark-mongo.py 
python data-mongo.py


/Users/tranan/Desktop/dev/spark/spark-3.5.1-bin-hadoop3/bin/spark-submit --packages org.mongodb.spark:mongo-spark-connector_2.12:3.0.2 Batch.py 

mongodb://admin:password@localhost:27017/iot?retryWrites=true&authSource=admin&readPreference=nearest
mongodb://root:Password123@mongodb:27017/test?retryWrites=true&w=majority&authSource=admin&readPreference=nearest

airflow standalone
DAG locate in /Users/tranan/airflow

Running
1. meter-producer.py 
2. spark-mongo.py 
3. data-mongo.py
4. /Users/tranan/Desktop/dev/spark/spark-3.5.1-bin-hadoop3/bin/spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1 \
  --master local\[4\] \
  Streaming.py
5. 